{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === colab configuration ===\n",
    "# Skip this cell if running demo file locally!\n",
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "\n",
    "# setting paths\n",
    "repository_path = '/content/time-series-forecasting-with-transformers/'\n",
    "dataset_path = repository_path + 'datasets/spx.csv'\n",
    "sys.path.insert(0, repository_path)\n",
    "\n",
    "# cloning project repository and downloading dataset\n",
    "# drive.mount('/content/drive')\n",
    "! test ! -d $repository_path && git clone https://github.com/francescobaraldi/time-series-forecasting-with-transformers\n",
    "# ! test ! -d $dataset_path && cp -R $dataset_path_drive $dataset_path\n",
    "%cd $repository_path\n",
    "\n",
    "# setting branch and pulling updates\n",
    "branch = 'main'\n",
    "! git checkout $branch\n",
    "! git pull origin $branch\n",
    "\n",
    "executing_on_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import StockDatasetSW\n",
    "from model import Transformer, DotProductAttention\n",
    "from eval_plot import eval, plot\n",
    "\n",
    "try:\n",
    "    executing_on_colab\n",
    "except NameError:\n",
    "    executing_on_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on attention operator\n",
    "d = 1\n",
    "model = DotProductAttention()\n",
    "queries = torch.rand((32, 7, d))\n",
    "keys = torch.rand((32, 7, d))\n",
    "values = torch.rand((32, 7, 1024))\n",
    "out = model(queries, keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not executing_on_colab:\n",
    "    dataset_path = \"datasets/spx.csv\"\n",
    "sp500 = pd.read_csv(dataset_path)\n",
    "sp500.head()\n",
    "plt.plot(sp500['close'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [datetime.datetime.strptime(date, '%Y-%m-%d').date() for date in sp500['Date']]\n",
    "dates = mdates.drange(dates[0], dates[-1], datetime.timedelta(days=30))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "plt.plot(dates, sp500['Close'])\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sp500['close'].to_numpy()\n",
    "data = torch.from_numpy(data).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "window_len = 7\n",
    "output_len = 1\n",
    "trainset = data[0:int(len(data) * 0.7)]\n",
    "testset = data[int(len(data) * 0.7):]\n",
    "train_dataset = StockDatasetSW(trainset, window_len, output_len)\n",
    "test_dataset = StockDatasetSW(testset, window_len, output_len)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "model = Transformer(seq_len=window_len, num_encoder=6, input_size=1, embed_dim=512, num_heads=1, feedforward_dim=1024).to(device)\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_maes = []\n",
    "test_maes = []\n",
    "\n",
    "for e in tqdm(range(epochs)):\n",
    "    model.eval()\n",
    "    \n",
    "    train_mae = eval(model, train_dl, device)\n",
    "    test_mae = eval(model, test_dl, device)\n",
    "    train_maes.append(train_mae.cpu())\n",
    "    test_maes.append(test_mae.cpu())\n",
    "    \n",
    "    print(f\"Epoch {e} - Train MAE {train_mae} - Test MAE {test_mae}\")\n",
    "    \n",
    "    model.train()\n",
    "    for i, (seq, trg) in enumerate(train_dl):\n",
    "        seq, trg = seq.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        seq_mask = torch.ones_like(seq)\n",
    "        out = model(seq, seq_mask)\n",
    "        loss = loss_fun(out, trg)\n",
    "        if i % 50 == 0:\n",
    "            print(f'loss {loss.cpu().item():.3f}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "plot(train_maes, test_maes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('schai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b91fdf7af299f1d8f043de0674e99b3c4b9e0e183f8c02fcd3b4107600a87665"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

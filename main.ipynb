{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === colab configuration ===\n",
    "# Skip this cell if running demo file locally!\n",
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "\n",
    "# setting paths\n",
    "repository_path = '/content/time-series-forecasting-with-transformers/'\n",
    "datasets_path = repository_path + 'datasets/'\n",
    "sys.path.insert(0, repository_path)\n",
    "\n",
    "# cloning project repository and downloading dataset\n",
    "drive.mount('/content/drive')\n",
    "! test ! -d $repository_path && git clone https://github.com/francescobaraldi/time-series-forecasting-with-transformers\n",
    "# ! test ! -d $dataset_path && cp -R $dataset_path_drive $dataset_path\n",
    "%cd $repository_path\n",
    "\n",
    "# setting branch and pulling updates\n",
    "branch = 'main'\n",
    "! git checkout $branch\n",
    "! git pull origin $branch\n",
    "\n",
    "! pip install yfinance\n",
    "\n",
    "executing_on_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import joblib\n",
    "import yfinance as yf\n",
    "\n",
    "from model import StockTransformerDecoder, StockTransformer, StockLSTM\n",
    "from inference import inference_transformer_decoder, inference_transformer, inference_lstm\n",
    "\n",
    "try:\n",
    "    executing_on_colab\n",
    "except NameError:\n",
    "    executing_on_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not executing_on_colab:\n",
    "    best_model_path = \"best_models/\"\n",
    "    scaler_path = \"weights/scaler_split_80.gz\"\n",
    "    inference_path = \"inference_results/\"\n",
    "else:\n",
    "    best_model_path = \"/content/drive/My Drive/time-series-forecasting-with-transformers/best_models/\"\n",
    "    scaler_path = \"/content/drive/My Drive/time-series-forecasting-with-transformers/weights/scaler_split_70.gz\"\n",
    "    inference_path = \"/content/drive/My Drive/time-series-forecasting-with-transformers/inference_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "window_len = 90\n",
    "forecast_len = 30\n",
    "\n",
    "transformer_decoder_args = {\n",
    "    'window_len': window_len,\n",
    "    'num_layers': 1,\n",
    "    'input_size': 1,\n",
    "    'output_size': 1,\n",
    "    'd_model': 128,\n",
    "    'num_heads': 8,\n",
    "    'feedforward_dim': 256,\n",
    "    'dropout': 0,\n",
    "    'positional_encoding': 'sinusoidal',\n",
    "}\n",
    "transformer_args = {\n",
    "    'window_len': window_len,\n",
    "    'target_len': forecast_len,\n",
    "    'num_encoder_layers': 1,\n",
    "    'num_decoder_layers': 1,\n",
    "    'input_size': 1,\n",
    "    'output_size': 1,\n",
    "    'd_model': 128,\n",
    "    'num_heads': 8,\n",
    "    'feedforward_dim': 256,\n",
    "    'dropout': 0,\n",
    "    'positional_encoding': 'sinusoidal',\n",
    "}\n",
    "lstm_args = {\n",
    "    'input_size': 1,\n",
    "    'hidden_dim': 64,\n",
    "    'output_size': 1,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0,\n",
    "}\n",
    "\n",
    "transformer_decoder = StockTransformerDecoder(**transformer_decoder_args)\n",
    "transformer = StockTransformer(**transformer_args)\n",
    "lstm = StockLSTM(**lstm_args)\n",
    "transformer_decoder.load_state_dict(torch.load(best_model_path + \"best_transformer_decoder.pth\", map_location=torch.device(device)))\n",
    "transformer.load_state_dict(torch.load(best_model_path + \"best_transformer.pth\", map_location=torch.device(device)))\n",
    "lstm.load_state_dict(torch.load(best_model_path + \"best_lstm.pth\", map_location=torch.device(device)))\n",
    "\n",
    "scaler = joblib.load(scaler_path)\n",
    "gspc = yf.Ticker(\"^GSPC\")\n",
    "gspc = gspc.history(period=\"1y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with transformer decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forecasting the SP500 index closing price for the next 30 days with transformer decoder model...\")\n",
    "    \n",
    "data = gspc[['Close']].iloc[-window_len:].to_numpy()\n",
    "scaler = joblib.load(scaler_path)\n",
    "data_scaled = scaler.transform(data)\n",
    "src = torch.from_numpy(data_scaled).float().unsqueeze(0)\n",
    "inference_transformer_decoder(device=device, model=transformer_decoder, src=src, forecast_len=forecast_len, scaler=scaler,\n",
    "                              save_path=inference_path + \"prediction_transformer_decoder.png\")\n",
    "\n",
    "print(f\"The prediction of the transformer decoder model has been saved correctly in folder {inference_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forecasting the SP500 index closing price for the next 30 days with transformer model...\")\n",
    "\n",
    "n = window_len + forecast_len - 1\n",
    "data = gspc[['Close']].iloc[-n:].to_numpy()\n",
    "scaler = joblib.load(scaler_path)\n",
    "data_scaled = scaler.transform(data)\n",
    "input = torch.from_numpy(data_scaled).float().unsqueeze(0)\n",
    "inference_transformer(device=device, model=transformer, input=input, window_len=window_len, forecast_len=forecast_len,\n",
    "                      scaler=scaler, save_path=inference_path + \"prediction_transformer.png\")\n",
    "\n",
    "print(f\"The prediction of the transformer model has been saved correctly in folder {inference_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forecasting the SP500 index closing price for the next 30 days with lstm model...\")\n",
    "    \n",
    "data = gspc[['Close']].iloc[-window_len:].to_numpy()\n",
    "scaler = joblib.load(scaler_path)\n",
    "data_scaled = scaler.transform(data)\n",
    "src = torch.from_numpy(data_scaled).float().unsqueeze(0)\n",
    "inference_lstm(device=device, model=lstm, src=src, forecast_len=forecast_len, scaler=scaler,\n",
    "               save_path=inference_path + \"prediction_lstm.png\")\n",
    "\n",
    "print(f\"The prediction of the lstm model has been saved correctly in folder {inference_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac88fb7088578c98ddf37923d050ab762e45c42e2a44ad2a5e146f45afe37fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
